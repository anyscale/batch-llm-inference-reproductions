model_id: neuralmagic/Meta-Llama-3.1-8B-Instruct-FP8
llm_engine: vllm
accelerator_type: L40S
engine_kwargs:
  tensor_parallel_size: 1
  pipeline_parallel_size: 1
  max_num_seqs: 224
  use_v2_block_manager: True
  enable_prefix_caching: False
  preemption_mode: "recompute"
  block_size: 16
  kv_cache_dtype: "auto"
  enforce_eager: False
  gpu_memory_utilization: 0.95
  enable_chunked_prefill: True
  max_num_batched_tokens: 3072
  max_seq_len_to_capture: 32768
runtime_env:
  env_vars:
    VLLM_ATTENTION_BACKEND: "FLASH_ATTN"
    ENABLE_ANYSCALE_PREFIX_OPTIMIZATIONS: "0"
